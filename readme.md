# Collection of my notes on neural network and practical examples

## :notebook: NN and DL :notebook:
### Theory
### Logistic Regression as a Neural Network
1. [Logistic Regression as a Neural Network](https://stomioka.github.io/deeplearning/docs/001-logistic-regression-as-a-neural-network.html)
2. [Cost Function](https://stomioka.github.io/deeplearning/docs/002-logistic-regression-cost-function.html)
3. [Gradient Descent](https://stomioka.github.io/deeplearning/docs/003-gradient-descent.html)
4. [Computational Graph](https://stomioka.github.io/deeplearning/docs/004-comuputational-graph.html)
5. [Logistic Regression Gradient Descent](https://stomioka.github.io/deeplearning/docs/005-logistic-regression-gradient-descent.html)
6. [Examples of Gradient Descent](https://stomioka.github.io/deeplearning/docs/006-gradient-descent-example.html)
### Python and Vectorization
7. [Vectorization](https://stomioka.github.io/deeplearning/docs/007-vectorization.html)
8. [Vectorized Implementation of Logistic Regression](https://stomioka.github.io/deeplearning/docs/008-vectorizing-logistic-regression.html)
9. [Computation of Vectorized Logistic Regressions Gradient](https://stomioka.github.io/deeplearning/docs/009-vectorizing-logistic-regressions-gradient-computation.html)
10. [Broadcasting in Python](https://stomioka.github.io/deeplearning/docs/010-broadcasting-in-python.html)
11. [Numpy Vectors](https://stomioka.github.io/deeplearning/docs/011-a-note-on-python-numpy-vectors.html)
12. [Justification of Logistic Regression Cost Function](https://stomioka.github.io/deeplearning/docs/012-Explanation-of-logistic-regression-cost-function.html)
### Shallow Neural Network
13. [Neural Networks Overview](https://stomioka.github.io/deeplearning/docs/013-neural-networks-overview.html)
14. [Vectorizing Implementation of Neural Network](https://stomioka.github.io/deeplearning/docs/014-vectorizing-across-multiple-examples.html)
15. [Activation Functions](https://stomioka.github.io/deeplearning/docs/015-activation-function.html)
16. [Derivatives of Activation Functions](https://stomioka.github.io/deeplearning/docs/016-derivatives-of-activation-functions.html)
17. [Gradient Descent for Neural Networks](https://stomioka.github.io/deeplearning/docs/017-gradient-descent-for-neural-networks.html)
18. [Random Initialization](https://stomioka.github.io/deeplearning/docs/018-random-initialization.html)
### Deep Neural Network
19. [Deep L-layer neural network](https://stomioka.github.io/deeplearning/docs/019-deep-l-layer-neural-network.html)
20. [Forward Propagation in a Deep Network](https://stomioka.github.io/deeplearning/docs/020-forward-propagation-in-a-deep-network.html)
21. [Getting matrix dimensions right](https://stomioka.github.io/deeplearning/docs/021-getting-matrix-dimensions-right.html)
22. [Why deep network?](https://stomioka.github.io/deeplearning/docs/022-why-deep-representations.html)
23. [Building blocks of deep neural networks](https://stomioka.github.io/deeplearning/docs/023-building-block-deep-neural-network.html)
24. [Forward and Backward Propagation](https://stomioka.github.io/deeplearning/docs/024-forward-and-backward-prpagation.html)
25. [Parameters vs Hyperparameters](https://stomioka.github.io/deeplearning/docs/025-parameters-hyperparameters.html)
26. [What does this have to do with the brain?](https://stomioka.github.io/deeplearning/docs/026-what-dows-this-have-to-do-with-the-brain.html)
### Machine Learning Application
27. [Train\Dev\Test sets](https://stomioka.github.io/deeplearning/docs/027-train-dev-test-sets.html)
28. [Bias and Variance Tradeoff](https://stomioka.github.io/deeplearning/docs/028-bias-variance.html)
29. [Basic Recipe for Machine Learning](https://stomioka.github.io/deeplearning/docs/029-basic-recipe-ml.html)
### Neural Network Regularization
30. [Regularization](https://stomioka.github.io/deeplearning/docs/030-regularization.html)
31. [Dropout Regularization](https://stomioka.github.io/deeplearning/docs/031-dropout-regularization.html)
32. [Other Regularization Methods](https://stomioka.github.io/deeplearning/docs/032-other-regularization-methods.html)
### Optimization problem
33. [Normalizing Inputs](https://stomioka.github.io/deeplearning/docs/033-normalizing-inputs.html)
34. [Vanishing Exploding Gradients](https://stomioka.github.io/deeplearning/docs/034-vanishing-exploding-gradients.html)
35. [Weight Initialization for Deep Networks](https://stomioka.github.io/deeplearning/docs/035-weight-initialization-for-deep-networks.html)
36. [Numerical approximation of gradients](https://stomioka.github.io/deeplearning/docs/036-numerical-approximation-of-gradients.html)
37. [Gradient Checking](https://stomioka.github.io/deeplearning/docs/037-gradient-checking.html)
### Optimization Algorithms
38. [Mini Batch Gradient](https://stomioka.github.io/deeplearning/docs/038-mini-batch-gradient.html)
39. [Exponentially weighted averages](https://stomioka.github.io/deeplearning/docs/039-exponentially-weighted-averages.html)
40. [Bias correction in exponentially weighted averages](https://stomioka.github.io/deeplearning/docs/040-bias-correction.html)
41. [Gradient descent with momentum](https://stomioka.github.io/deeplearning/docs/041-gradient-descent-with-momentum.html)
42. [Optimization Algorithms RMSprop](https://stomioka.github.io/deeplearning/docs/042-rmsprop.html)
43. [Optimization Algorithms Adam](https://stomioka.github.io/deeplearning/docs/043-adam.html)
44. [Learning rate decay](https://stomioka.github.io/deeplearning/docs/044-learning-rate-decay.html)
45. [Local optima](https://stomioka.github.io/deeplearning/docs/045-local-optima.html)
### Hyperparameter tuning
46. [Tuning Process](https://stomioka.github.io/deeplearning/docs/046-tuning-process.html)
### Batch Normalization
47. [Normalizing activations in a network](https://stomioka.github.io/deeplearning/docs/047-normalizing-activations-in-network.html)
48. [Fitting Batch Norm into a neural network](https://stomioka.github.io/deeplearning/docs/048-fitting-batch-norm.html)
49. [Why does Batch Norm work?](https://stomioka.github.io/deeplearning/docs/049-why-batch-norm-work.html)
50. [Batch Norm at test time](https://stomioka.github.io/deeplearning/docs/050-batch-norm-at-test-time.html)

### Multi-class classification
51. [Softmax Regression](https://stomioka.github.io/deeplearning/docs/051-softmax-regression.html)
52. [Training a softmax classifier](https://stomioka.github.io/deeplearning/docs/052-training-softmax-classifier.html)

### Deeplearning Programming Framework
53. [Deeplearning programming framework](https://stomioka.github.io/deeplearning/docs/053-deeplearning-prog-framework.html)
54. [TensorFlow](./python-examples/054-tensorflow.ipynb)

## :notebook: ML in Practice :notebook:
### ML Strategy
55. [Why Machine Learning Strategy](https://stomioka.github.io/deeplearning/docs/055-ml-strategy.html)
56. [Orthogonalization](https://stomioka.github.io/deeplearning/docs/056-orthogonalization.html)
### Goal Setting
57. [Single number evaluation metric](https://stomioka.github.io/deeplearning/docs/057-single-number-evaluation-metric.html)
58. [Satisficing and Optimizing metric](https://stomioka.github.io/deeplearning/docs/058-optimizing-metric.html)
59. [Train/dev/test distributions](https://stomioka.github.io/deeplearning/docs/059-train_dev_test_distribution.html)
60. [Size of dev/test data](https://stomioka.github.io/deeplearning/docs/060-dev-test-data-size.html)
61. [When to change dev/test sets and metrics](https://stomioka.github.io/deeplearning/docs/061-dev-test-metrics.html)

### Comparing to human-level performance
62. [Why human-level performance?](https://stomioka.github.io/deeplearning/docs/062-human-level-performance.html)
63. [Avoidable bias](https://stomioka.github.io/deeplearning/docs/063-avoidable-bias.html)
64. [Understanding human-level performance](https://stomioka.github.io/deeplearning/docs/064-understanding-human-level-performance.html)
65. [Surpassing human-level performance](https://stomioka.github.io/deeplearning/docs/065-surpassing-human-level-performance.html)
66. [Improving your model performance](https://stomioka.github.io/deeplearning/docs/066-improving-model-performance.html)

### Error Analysis
67. [Error analysis](https://stomioka.github.io/deeplearning/docs/067-error-analysis.html)
68. [Cleaning incorrectly labeled data](https://stomioka.github.io/deeplearning/docs/068-cleaning-incorrectly-labeled-data.html)
69. [Build system quickly then iterate](https://stomioka.github.io/deeplearning/docs/069-build-iterate.html)

### Mismatched training and dev/test set
70. [Training and testing on different distributions](https://stomioka.github.io/deeplearning/docs/070-train-test-diff-distributions.html)
71. [Bias and Variance with mismatched data distributions](https://stomioka.github.io/deeplearning/docs/071-bias-variance-mistmatched-data-distributions.html)
72. [Addressing data mismatch](https://stomioka.github.io/deeplearning/docs/072-address-data-mismatch.html)

### Learning from multiple tasks
73. [Transfer learning](https://stomioka.github.io/deeplearning/docs/073-transfer-learning.html)
74. [Multi-task learning](https://stomioka.github.io/deeplearning/docs/074-multi-task-learning.html)

### End-to-end deep learning
75. [What is end to end deep learning](https://stomioka.github.io/deeplearning/docs/075-end-to-end-learning.html)
76. [Whether to use end to end deep learning](https://stomioka.github.io/deeplearning/docs/076-end-to-end-learning.html)

## :notebook: Convolutional Neural Nets :notebook:
### Theory
77. [Computer Vision](https://stomioka.github.io/deeplearning/docs/077-computer-vision.html)
78. [Edge Detection](https://stomioka.github.io/deeplearning/docs/078-edge-detection.html)
79. [Padding](https://stomioka.github.io/deeplearning/docs/079-padding.html)
80. [Strided Convolution](https://stomioka.github.io/deeplearning/docs/080-stride-convolution.html)
81. [Convolutions Over Volume](https://stomioka.github.io/deeplearning/docs/081-convolution-over-volume.html)
82. [One Layer Convolutional Network](https://stomioka.github.io/deeplearning/docs/082-one-layer-convolution.html)
83. [Simple Convolutional Network](https://stomioka.github.io/deeplearning/docs/083-simple-cnn.html)
84. [Pooling Layer](https://stomioka.github.io/deeplearning/docs/084-pooling.html)
85. [CNN Example](https://stomioka.github.io/deeplearning/docs/085-cnn-example.html)
86. [Why Convolutions are useful?](https://stomioka.github.io/deeplearning/docs/086-why-convolutions.html)
### Deep convolutional models: case studies
87. [LeNet-5, ALexNet, VGG-16](https://stomioka.github.io/deeplearning/docs/087-classic-networks.html)
88. [ResNets](https://stomioka.github.io/deeplearning/docs/088-resnets.html)
89. [Networks in Networks and 1x1 Convolutions](https://stomioka.github.io/deeplearning/docs/089-1-1-convolutions.html)
90. [GoogLeNet: Inception Network](https://stomioka.github.io/deeplearning/docs/090-inception-network.html)

### ConvNet in Practice
91. [Data Augmentation](https://stomioka.github.io/deeplearning/docs/091-data-argumentation.html)
92. [State of Computer Vision](https://stomioka.github.io/deeplearning/docs/092-computer-vision.html)

### Object Detectction
93. [Object Lcoalization](https://stomioka.github.io/deeplearning/docs/093-object-localization.html)
94. [Landmark Detection](https://stomioka.github.io/deeplearning/docs/094-landmark-detection.html)
95. [Object Detection](https://stomioka.github.io/deeplearning/docs/095-object-detection.html)
96. [Convolutional Implementation of Sliding Windows](https://stomioka.github.io/deeplearning/docs/096-sliding-window-in-convolution.html)
97. [YOLO algorithm](https://stomioka.github.io/deeplearning/docs/097-bounding-box-predictions.html)
98. [IoU](https://stomioka.github.io/deeplearning/docs/098-intersection-over-union.html)
99. [Non max suppression](https://stomioka.github.io/deeplearning/docs/099-non-max-suppression.html)
100. [Anchor Boxes](https://stomioka.github.io/deeplearning/docs/100-anchor-boxes.html)
101. [R-CNN](https://stomioka.github.io/deeplearning/docs/101-region-proposals.html)

### Special applications: Face recognition & Neural style transfer
102. [Face Recognition](https://stomioka.github.io/deeplearning/docs/102-face-recognition.html)
103. [neural style transfer](https://stomioka.github.io/deeplearning/docs/103-neural-style-transfer.html)
104. [Convolutional Networks in 1D and 3D](https://stomioka.github.io/deeplearning/docs/104-1d3dgeneralizations.html)

# Sequence models
105. [Sequence Data Examples](https://stomioka.github.io/deeplearning/docs/105-sequence-model.html)

## RNN
106. [Notations](https://stomioka.github.io/deeplearning/docs/106-notations.html)
107. [Recurrent Neural Network Model](https://stomioka.github.io/deeplearning/docs/107-rnnmodels.html)
108. [Language model and sequence generation](https://stomioka.github.io/deeplearning/docs/108-language-model.html)
109. [Sampling novel sequences](https://stomioka.github.io/deeplearning/docs/109-language-model.html)
110. [GRU](https://stomioka.github.io/deeplearning/docs/111-gru.html)
111. [LSTM](https://stomioka.github.io/deeplearning/docs/111-lstm.html)
112. [Bidirectional RNN](https://stomioka.github.io/deeplearning/docs/112-birnn.html)

## Word Embedding
113. [Word Representation](https://stomioka.github.io/deeplearning/docs/113-word-representation.html)
114. [Learning word embeddings](https://stomioka.github.io/deeplearning/docs/114-word-embeddings.html)
115. [Nueral Network Language model](https://stomioka.github.io/deeplearning/docs/l001-language-models.html)
116. [Word2Vec](https://stomioka.github.io/deeplearning/docs/116-word2vec.html)
117. [GloVe](https://stomioka.github.io/deeplearning/docs/117-glove.html)
118. [Debiasing word embedding](https://stomioka.github.io/deeplearning/docs/118-debiasing.html)



## Sequence to Sequence model

119. [Basic Model](https://stomioka.github.io/deeplearning/docs/119-basic-model.html)
120. [Picking the most likely sentence](https://stomioka.github.io/deeplearning/docs/120-most-likely-sentence.html)
121. [Beam Search Algorithm](https://stomioka.github.io/deeplearning/docs/121-beam-search.html)
122. [Error Analysis in Beam Search](https://stomioka.github.io/deeplearning/docs/122-error-analysis.html)
123. [Attention Model](https://stomioka.github.io/deeplearning/docs/123-attention-model.html)
124. [Speech Recognition](https://stomioka.github.io/deeplearning/docs/124-speech-recognition.html)

##  Generative Adversarial Nets
- [GAN](https://stomioka.github.io/deeplearning/docs/gan.html)
- [BiGAN](https://stomioka.github.io/deeplearning/docs/bigan.html)
-
### Applied GAN
- [GAN for anormaly detection](https://stomioka.github.io/deeplearning/docs/)
  - AnoGAN
  - EGBAD

## Summation of Important Papers
- [Word2vec]
- [FastText]
- [Elmo]
- [seq2seq](https://stomioka.github.io/deeplearning/docs/l004-seq2seq.html)
- [Transformer](https://stomioka.github.io/deeplearning/docs/l006-transformer.html)
- [Universal Language Model Fine-tuning for Text Classification]()
- [Tranformer XL]
- [Universal Sentence Encoder]([https://stomioka.github.io/deeplearning/docs/](https://stomioka.github.io/deeplearning/docs/131-use.html)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding]
- [GPT2]
- [MN-DDN]
- [XLNet]

## TensorFlow Basic
- [Using Callbacks to control training](docs/01-tf-callbacks.md)
- [Simple covnet](docs/01-tf-convenet.md)
- [MNIST classification example](python-examples/mnist_convolutions_with_callback.ipynb)
- [Convnet with TF](docs/02-tf-convnet.md)
- [Image augmentation](docs/03-tf-augmentation.md)

## NLP in TensorFlow
- [Sentiment Analysis](docs/04-tf-sentiment.md)
- [Embeddings](docs/05-tf-embeddings.md)
- [Sentiment Analysis - Embeddings](nlp-tasks/Sarcasm_sentiment_analysis_embeddings.ipynb)
- [IMDB Subwords 8K with Single Layer LSTM](nlp-tasks/tf_single_layer_lstm.ipynb)
- [IMDB Subwords 8K with Multi Layer LSTM](nlp-tasks/multilayer_lstm.ipynb)
- [IMDB Subwords 8K with 1D Convolutional Layer](nlp-tasks/1d_covolution.ipynb)
- [Sarcasm with Bidirectional LSTM](nlp-tasks/bidirectional_lstm.ipynb)
- [Sarcasm with 1D Convolutional Layer](nlp-tasks/gru.ipynb)
- [Generating Text](nlp-tasks/generate_text1.ipynb)

## Sequence/time series and predictions
- [examples](time-series/01-examples.md)
- [Common patterns in time series](time-series/02-common-example.md)
- [Train, validation, and test](time-series/03-train-valid-test.md)
- [Metrics for evaluating performance](time-series/04-metrics.md)
- [Moving average and differencing](time-series/05-moving-avg.md)
- [Trailing versus centered windows](time-series/06-trailing.md)
- [Statistical Forecasting](time-series/07-forecasting.md)
- [Time series Forecasting Notebook](time-series/timeseriese_forcast.ipynb)

## Deep neural network for time series
- [Preparing features and labels](time-series/prep-features-labels.md)
- [Sequence bias](time-series/sequence-bias.md)
- [Feeding windowed dataset into neural networks](time-series/feeding-win-nn.md)
- [Single layer neural network](time-series/sl-nn.md)
- [Machine learning on time windows](time-series/ml-tw.md)
- [Prediction](time-series/pred.md)
- [More on single layer neural network](time-series/more-sl-nn.md)
- [Deep neural network training, tuning and prediction](time-series/dnn-train-pred.md)
- [RNN for time series](time-series/rnnfortimeseries.md)

## Real-world time series data
- [Convolutions+LSTM](time-series/convnet.md)
- [Real data sunspots](time-series/sunspots.md)
- [Train and tune the model]
- [Prediction]
- [SUnspots]
- [Combining ur tools for analysis]
-


## Implementations in Python and R

###  Implementations in R:
1. [Neural Network Classification](https://rpubs.com/stomioka/nnclassification)
2. [Simple 2 hidden layer network with Keras](https://rpubs.com/stomioka/399650)

### Implementations in Python:
1. [Building an image recognition algorithm using logistic regression with neural network mindset](python-examples/build-image-recog-algorithm-lr-nn.ipynb)
2. [Building a 2 layer neural network for binary classification problem](python-examples/build-binary-classification-2-layer-neural-network.ipynb)
3. [Building neural network utilities](python-examples/building-deep-learning-utils.ipynb)
4. [Building a 2 layer neural network and deep learning neural network from scratch](python-examples/build-binary-classification-2-layer-neural-network.ipynb)
5. [Initialization](python-examples/initializations.ipynb)
    - initialize_parameters_zeros
    - initialize_parameters_random
    - initialize_parameters_he
6. [Regularization](python-examples/regularization.ipynb)
    - compute_cost_with_regularization
    - backward_propagation_with_regularization
    - forward_propagation_with_dropout
    - backward_propagation_with_dropout
7. [Gradient Checking](python-examples/gradient-checking.ipynb)
    - gradient_check
    - gradient_check_n
8. [Optimization](python-examples/optimization.ipynb)
    - update_parameters_with_gd
    - random_mini_batches
    - initialize_velocity
    - update_parameters_with_momentum
    - initialize_adam
    - update_parameters_with_adam
9. [TensorFlow: Build neural network for multiclassification problem](python-examples/tf-tutorial.ipynb)
10. [Building Convnet with numpy](python-examples/convnet-with-numpy.ipynb)
11. [Building Convnet with TensorFlow](python-examples/convnet-with-tensorflow.ipynb)
12. [Building ResNets with Keras](python-examples/resnets.ipynb)
13. [AEDECOD and AETERM similarity with Universal Sentence Encoder with Transformer](python-examples/use-keras.ipynb)
14. [Objects detection using pre-trained Yolo weights](python-examples/object-detection-yolo.ipynb)
15. [Neural Style Transfer](neuraltransfer/neural-transfer.ipynb)
16. [Face Recognition](facerecognition/face-recognition.ipynb)
17. [Character level language moodel - LSTM](character-level-language-model/build_model.ipynb)
18. [Generate Text - LSTM](character-level-language-model/gen_sentence.ipynb)
19. [NLP tasks](nlp-tasks\similarity_analogy.ipynb)
